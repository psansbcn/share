{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0a0501",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f25c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba18c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718c78b",
   "metadata": {},
   "source": [
    "##### Load the SQL db for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6766d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect(\"parametres.db\")\n",
    "cur=conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542562d4",
   "metadata": {},
   "source": [
    "##### Load database sampled to a 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b592759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48419 entries, 158705 to 475174\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ActualElapsedTime  48419 non-null  float64\n",
      " 1   AirTime            48419 non-null  float64\n",
      " 2   ArrDelay           48419 non-null  int64  \n",
      " 3   DepDelay           48419 non-null  float64\n",
      " 4   Distance           48419 non-null  float64\n",
      " 5   TaxiIn             48419 non-null  float64\n",
      " 6   TaxiOut            48419 non-null  float64\n",
      " 7   Cancelled          48419 non-null  float64\n",
      " 8   Diverted           48419 non-null  int64  \n",
      " 9   CarrierDelay       48419 non-null  float64\n",
      " 10  WeatherDelay       48419 non-null  float64\n",
      " 11  NASDelay           48419 non-null  float64\n",
      " 12  SecurityDelay      48419 non-null  float64\n",
      " 13  LateAircraftDelay  48419 non-null  float64\n",
      " 14  DepTime_sin        48419 non-null  float64\n",
      " 15  DepTime_cos        48419 non-null  float64\n",
      " 16  Month_sin          48419 non-null  float64\n",
      " 17  Month_cos          48419 non-null  float64\n",
      " 18  DayOfWeek_sin      48419 non-null  float64\n",
      " 19  DayOfWeek_cos      48419 non-null  float64\n",
      " 20  origin_freq        48419 non-null  float64\n",
      " 21  dest               48419 non-null  float64\n",
      " 22  carrier_me         48419 non-null  float64\n",
      "dtypes: float64(21), int64(2)\n",
      "memory usage: 8.9 MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('delayed25.csv', index_col=False, warn_bad_lines=True, error_bad_lines=False)\n",
    "# as the process take too much time, we resample the database \n",
    "df = df.sample(frac =.1)\n",
    "df=df.drop(['Unnamed: 0'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58cfd8",
   "metadata": {},
   "source": [
    "##### Split attibutes and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71065ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>...</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "      <th>DepTime_sin</th>\n",
       "      <th>DepTime_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>DayOfWeek_sin</th>\n",
       "      <th>DayOfWeek_cos</th>\n",
       "      <th>origin_freq</th>\n",
       "      <th>dest</th>\n",
       "      <th>carrier_me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>4.841900e+04</td>\n",
       "      <td>4.841900e+04</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "      <td>48419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499586</td>\n",
       "      <td>0.500283</td>\n",
       "      <td>41.853880</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>0.497787</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>-0.396306</td>\n",
       "      <td>-0.277026</td>\n",
       "      <td>1.053203e-01</td>\n",
       "      <td>2.822428e-02</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>0.340081</td>\n",
       "      <td>0.336523</td>\n",
       "      <td>0.762627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288631</td>\n",
       "      <td>0.288050</td>\n",
       "      <td>54.697786</td>\n",
       "      <td>0.044838</td>\n",
       "      <td>0.131367</td>\n",
       "      <td>0.287209</td>\n",
       "      <td>0.288041</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.060690</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031210</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>0.625765</td>\n",
       "      <td>6.596759e-01</td>\n",
       "      <td>7.436123e-01</td>\n",
       "      <td>0.706132</td>\n",
       "      <td>0.725226</td>\n",
       "      <td>0.307294</td>\n",
       "      <td>0.291003</td>\n",
       "      <td>0.138885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-0.015817</td>\n",
       "      <td>-0.132231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.384455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.247247</td>\n",
       "      <td>0.249259</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.010545</td>\n",
       "      <td>-0.061065</td>\n",
       "      <td>0.250257</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.918791</td>\n",
       "      <td>-0.856718</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.801938</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.104784</td>\n",
       "      <td>0.111787</td>\n",
       "      <td>0.659196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498518</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559574</td>\n",
       "      <td>0.475976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.623197</td>\n",
       "      <td>-0.425779</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.235995</td>\n",
       "      <td>0.258176</td>\n",
       "      <td>0.819271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.751251</td>\n",
       "      <td>0.749279</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>0.089761</td>\n",
       "      <td>0.749269</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>0.278991</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.801938</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.431925</td>\n",
       "      <td>0.448304</td>\n",
       "      <td>0.860134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ActualElapsedTime       AirTime      ArrDelay      DepDelay  \\\n",
       "count       48419.000000  48419.000000  48419.000000  48419.000000   \n",
       "mean            0.499586      0.500283     41.853880      0.016447   \n",
       "std             0.288631      0.288050     54.697786      0.044838   \n",
       "min             0.000240      0.000188    -53.000000     -0.015817   \n",
       "25%             0.247247      0.249259      9.000000     -0.010545   \n",
       "50%             0.500000      0.498518     25.000000      0.000000   \n",
       "75%             0.751251      0.749279     56.000000      0.025483   \n",
       "max             1.000000      1.000000   1143.000000      1.000000   \n",
       "\n",
       "           Distance        TaxiIn       TaxiOut     Cancelled      Diverted  \\\n",
       "count  48419.000000  48419.000000  48419.000000  48419.000000  48419.000000   \n",
       "mean       0.036253      0.502837      0.497787      0.000310      0.003697   \n",
       "std        0.131367      0.287209      0.288041      0.017598      0.060690   \n",
       "min       -0.132231      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       -0.061065      0.250257      0.222222      0.000000      0.000000   \n",
       "50%        0.000000      0.559574      0.475976      0.000000      0.000000   \n",
       "75%        0.089761      0.749269      0.752252      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       CarrierDelay  ...  LateAircraftDelay   DepTime_sin   DepTime_cos  \\\n",
       "count  48419.000000  ...       48419.000000  48419.000000  48419.000000   \n",
       "mean       0.012662  ...           0.014252     -0.396306     -0.277026   \n",
       "std        0.035075  ...           0.031210      0.612072      0.625765   \n",
       "min        0.000000  ...           0.000000     -1.000000     -1.000000   \n",
       "25%        0.000000  ...           0.000000     -0.918791     -0.856718   \n",
       "50%        0.000000  ...           0.000000     -0.623197     -0.425779   \n",
       "75%        0.009564  ...           0.015748     -0.010472      0.278991   \n",
       "max        1.000000  ...           1.000000      1.000000      1.000000   \n",
       "\n",
       "          Month_sin     Month_cos  DayOfWeek_sin  DayOfWeek_cos   origin_freq  \\\n",
       "count  4.841900e+04  4.841900e+04   48419.000000   48419.000000  48419.000000   \n",
       "mean   1.053203e-01  2.822428e-02       0.002986      -0.011282      0.340081   \n",
       "std    6.596759e-01  7.436123e-01       0.706132       0.725226      0.307294   \n",
       "min   -1.000000e+00 -1.000000e+00      -1.000000      -0.900969      0.000076   \n",
       "25%   -5.000000e-01 -8.660254e-01      -0.801938      -0.900969      0.104784   \n",
       "50%    1.224647e-16  6.123234e-17       0.000000      -0.222521      0.235995   \n",
       "75%    8.660254e-01  8.660254e-01       0.801938       0.623490      0.431925   \n",
       "max    1.000000e+00  1.000000e+00       1.000000       1.000000      1.000000   \n",
       "\n",
       "               dest    carrier_me  \n",
       "count  48419.000000  48419.000000  \n",
       "mean       0.336523      0.762627  \n",
       "std        0.291003      0.138885  \n",
       "min        0.000110      0.384455  \n",
       "25%        0.111787      0.659196  \n",
       "50%        0.258176      0.819271  \n",
       "75%        0.448304      0.860134  \n",
       "max        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = ['ArrDelay'] \n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf22ce",
   "metadata": {},
   "source": [
    "##### Train i test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cb264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33893, 22)\n",
      "(14526, 22)\n"
     ]
    }
   ],
   "source": [
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5526ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               2300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model previously tested with Kaggle\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=22, activation='relu'))\n",
    "# check to see if the regression node should be added\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary() #Print model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a8d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1060/1060 [==============================] - 9s 800us/step - loss: 4125.5968 - mean_squared_error: 4125.5968\n",
      "Epoch 2/200\n",
      "1060/1060 [==============================] - 1s 803us/step - loss: 2671.3494 - mean_squared_error: 2671.3494\n",
      "Epoch 3/200\n",
      "1060/1060 [==============================] - 1s 832us/step - loss: 1665.2918 - mean_squared_error: 1665.2918\n",
      "Epoch 4/200\n",
      "1060/1060 [==============================] - 1s 843us/step - loss: 797.0644 - mean_squared_error: 797.0644\n",
      "Epoch 5/200\n",
      "1060/1060 [==============================] - 1s 855us/step - loss: 284.3680 - mean_squared_error: 284.3680\n",
      "Epoch 6/200\n",
      "1060/1060 [==============================] - 1s 846us/step - loss: 138.8817 - mean_squared_error: 138.8817\n",
      "Epoch 7/200\n",
      "1060/1060 [==============================] - 1s 858us/step - loss: 103.0801 - mean_squared_error: 103.0801\n",
      "Epoch 8/200\n",
      "1060/1060 [==============================] - 1s 874us/step - loss: 93.3496 - mean_squared_error: 93.3496\n",
      "Epoch 9/200\n",
      "1060/1060 [==============================] - 1s 880us/step - loss: 62.3041 - mean_squared_error: 62.3041\n",
      "Epoch 10/200\n",
      "1060/1060 [==============================] - 1s 889us/step - loss: 69.9108 - mean_squared_error: 69.9108\n",
      "Epoch 11/200\n",
      "1060/1060 [==============================] - 1s 891us/step - loss: 65.8052 - mean_squared_error: 65.8052\n",
      "Epoch 12/200\n",
      "1060/1060 [==============================] - 1s 936us/step - loss: 52.6452 - mean_squared_error: 52.6452\n",
      "Epoch 13/200\n",
      "1060/1060 [==============================] - 1s 932us/step - loss: 47.4770 - mean_squared_error: 47.4770\n",
      "Epoch 14/200\n",
      "1060/1060 [==============================] - 1s 955us/step - loss: 51.8077 - mean_squared_error: 51.8077\n",
      "Epoch 15/200\n",
      "1060/1060 [==============================] - 1s 954us/step - loss: 45.2907 - mean_squared_error: 45.2907\n",
      "Epoch 16/200\n",
      "1060/1060 [==============================] - 1s 976us/step - loss: 41.7901 - mean_squared_error: 41.7901\n",
      "Epoch 17/200\n",
      "1060/1060 [==============================] - 1s 975us/step - loss: 42.0889 - mean_squared_error: 42.0889\n",
      "Epoch 18/200\n",
      "1060/1060 [==============================] - 1s 995us/step - loss: 45.0057 - mean_squared_error: 45.0057\n",
      "Epoch 19/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 41.0152 - mean_squared_error: 41.0152\n",
      "Epoch 20/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.2543 - mean_squared_error: 42.2543\n",
      "Epoch 21/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.0990 - mean_squared_error: 39.0990\n",
      "Epoch 22/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 41.7358 - mean_squared_error: 41.7358\n",
      "Epoch 23/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.5237 - mean_squared_error: 38.5237\n",
      "Epoch 24/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.2650 - mean_squared_error: 38.2650\n",
      "Epoch 25/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.6103 - mean_squared_error: 40.6103\n",
      "Epoch 26/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.7065 - mean_squared_error: 38.7065\n",
      "Epoch 27/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.5138 - mean_squared_error: 43.5138\n",
      "Epoch 28/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.6667 - mean_squared_error: 37.6667\n",
      "Epoch 29/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.2206 - mean_squared_error: 38.2206\n",
      "Epoch 30/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.6850 - mean_squared_error: 40.6850\n",
      "Epoch 31/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.2318 - mean_squared_error: 38.2318\n",
      "Epoch 32/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.0681 - mean_squared_error: 38.0681\n",
      "Epoch 33/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.9025 - mean_squared_error: 36.9025\n",
      "Epoch 34/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.0528 - mean_squared_error: 37.0528\n",
      "Epoch 35/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.0728 - mean_squared_error: 39.0728\n",
      "Epoch 36/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.3717 - mean_squared_error: 35.3717\n",
      "Epoch 37/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.4558 - mean_squared_error: 43.4558\n",
      "Epoch 38/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.1095 - mean_squared_error: 38.1095\n",
      "Epoch 39/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.5093 - mean_squared_error: 40.5093\n",
      "Epoch 40/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.1486 - mean_squared_error: 36.1486\n",
      "Epoch 41/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.3955 - mean_squared_error: 39.3955\n",
      "Epoch 42/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.4386 - mean_squared_error: 35.4386\n",
      "Epoch 43/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.9500 - mean_squared_error: 36.9500\n",
      "Epoch 44/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.0979 - mean_squared_error: 35.0979\n",
      "Epoch 45/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.4633 - mean_squared_error: 37.4633: 0s - loss: 3\n",
      "Epoch 46/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.0490 - mean_squared_error: 40.0490\n",
      "Epoch 47/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.0392 - mean_squared_error: 38.0392\n",
      "Epoch 48/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.8863 - mean_squared_error: 33.8863\n",
      "Epoch 49/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.9694 - mean_squared_error: 37.9694\n",
      "Epoch 50/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.8288 - mean_squared_error: 32.8288\n",
      "Epoch 51/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.9457 - mean_squared_error: 35.9457\n",
      "Epoch 52/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.0333 - mean_squared_error: 39.0333\n",
      "Epoch 53/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.8424 - mean_squared_error: 39.8424\n",
      "Epoch 54/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.1106 - mean_squared_error: 37.1106\n",
      "Epoch 55/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.0274 - mean_squared_error: 38.0274\n",
      "Epoch 56/200\n",
      "1060/1060 [==============================] - 2s 2ms/step - loss: 31.9314 - mean_squared_error: 31.9314\n",
      "Epoch 57/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.1227 - mean_squared_error: 35.1227\n",
      "Epoch 58/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.5186 - mean_squared_error: 35.5186\n",
      "Epoch 59/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.9856 - mean_squared_error: 36.9856\n",
      "Epoch 60/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.3401 - mean_squared_error: 36.3401\n",
      "Epoch 61/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.7322 - mean_squared_error: 39.7322\n",
      "Epoch 62/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.6488 - mean_squared_error: 36.6488\n",
      "Epoch 63/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.9904 - mean_squared_error: 35.9904\n",
      "Epoch 64/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.9647 - mean_squared_error: 32.9647\n",
      "Epoch 65/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.7593 - mean_squared_error: 33.7593\n",
      "Epoch 66/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.7116 - mean_squared_error: 40.7116: 0s - loss: 41.7276 - mean_squared_er\n",
      "Epoch 67/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.9059 - mean_squared_error: 34.9059\n",
      "Epoch 68/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.4124 - mean_squared_error: 38.4124\n",
      "Epoch 69/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.8506 - mean_squared_error: 37.8506\n",
      "Epoch 70/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.8875 - mean_squared_error: 34.8875\n",
      "Epoch 71/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.0647 - mean_squared_error: 35.0647\n",
      "Epoch 72/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.9904 - mean_squared_error: 38.9904\n",
      "Epoch 73/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 34.5975 - mean_squared_error: 34.5975\n",
      "Epoch 74/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.2959 - mean_squared_error: 34.2959\n",
      "Epoch 75/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.9532 - mean_squared_error: 34.9532\n",
      "Epoch 76/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.7789 - mean_squared_error: 38.7789\n",
      "Epoch 77/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.4669 - mean_squared_error: 34.4669\n",
      "Epoch 78/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 37.1431 - mean_squared_error: 37.1431\n",
      "Epoch 79/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.3631 - mean_squared_error: 32.3631\n",
      "Epoch 80/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.5774 - mean_squared_error: 33.5774\n",
      "Epoch 81/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.2072 - mean_squared_error: 36.2072\n",
      "Epoch 82/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.2164 - mean_squared_error: 33.2164\n",
      "Epoch 83/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.2954 - mean_squared_error: 33.2954\n",
      "Epoch 84/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.1601 - mean_squared_error: 32.1601\n",
      "Epoch 85/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.2727 - mean_squared_error: 33.2727\n",
      "Epoch 86/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.2143 - mean_squared_error: 33.2143\n",
      "Epoch 87/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 33.8865 - mean_squared_error: 33.8865\n",
      "Epoch 88/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.6259 - mean_squared_error: 34.6259\n",
      "Epoch 89/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 31.5483 - mean_squared_error: 31.5483\n",
      "Epoch 90/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 36.1776 - mean_squared_error: 36.1776\n",
      "Epoch 91/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.5478 - mean_squared_error: 32.5478\n",
      "Epoch 92/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 30.7636 - mean_squared_error: 30.7636\n",
      "Epoch 93/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.5837 - mean_squared_error: 32.5837\n",
      "Epoch 94/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.0158 - mean_squared_error: 29.0158\n",
      "Epoch 95/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 35.3774 - mean_squared_error: 35.3774\n",
      "Epoch 96/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 31.1830 - mean_squared_error: 31.1830\n",
      "Epoch 97/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 30.1175 - mean_squared_error: 30.1175\n",
      "Epoch 98/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 34.5955 - mean_squared_error: 34.5955\n",
      "Epoch 99/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 32.0417 - mean_squared_error: 32.0417\n",
      "Epoch 100/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.7792 - mean_squared_error: 28.7792\n",
      "Epoch 101/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 31.6329 - mean_squared_error: 31.6329\n",
      "Epoch 102/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.8540 - mean_squared_error: 29.8540\n",
      "Epoch 103/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.3759 - mean_squared_error: 29.3759\n",
      "Epoch 104/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 30.5674 - mean_squared_error: 30.5674\n",
      "Epoch 105/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.4669 - mean_squared_error: 28.4669\n",
      "Epoch 106/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.3886 - mean_squared_error: 29.3886\n",
      "Epoch 107/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 31.3216 - mean_squared_error: 31.3216\n",
      "Epoch 108/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.0746 - mean_squared_error: 29.0746\n",
      "Epoch 109/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.3624 - mean_squared_error: 29.3624\n",
      "Epoch 110/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.1876 - mean_squared_error: 28.1876\n",
      "Epoch 111/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 30.1007 - mean_squared_error: 30.1007\n",
      "Epoch 112/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.1217 - mean_squared_error: 28.1217\n",
      "Epoch 113/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.6766 - mean_squared_error: 27.6766\n",
      "Epoch 114/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.9300 - mean_squared_error: 27.9300\n",
      "Epoch 115/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.9544 - mean_squared_error: 27.9544\n",
      "Epoch 116/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 29.4957 - mean_squared_error: 29.4957\n",
      "Epoch 117/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.2714 - mean_squared_error: 28.2714\n",
      "Epoch 118/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.2552 - mean_squared_error: 27.2552\n",
      "Epoch 119/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.3995 - mean_squared_error: 28.3995\n",
      "Epoch 120/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.1261 - mean_squared_error: 27.1261: 0s - loss: 27.14\n",
      "Epoch 121/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.7644 - mean_squared_error: 27.7644\n",
      "Epoch 122/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 28.2639 - mean_squared_error: 28.2639\n",
      "Epoch 123/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.9168 - mean_squared_error: 27.9168\n",
      "Epoch 124/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 27.6108 - mean_squared_error: 27.6108\n",
      "Epoch 125/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.9313 - mean_squared_error: 26.9313\n",
      "Epoch 126/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.9445 - mean_squared_error: 26.9445\n",
      "Epoch 127/200\n",
      "1060/1060 [==============================] - 2s 2ms/step - loss: 28.8768 - mean_squared_error: 28.8768\n",
      "Epoch 128/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 25.4730 - mean_squared_error: 25.4730\n",
      "Epoch 129/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 27.6977 - mean_squared_error: 27.6977\n",
      "Epoch 130/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.5830 - mean_squared_error: 26.5830\n",
      "Epoch 131/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.9788 - mean_squared_error: 24.9788\n",
      "Epoch 132/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.5670 - mean_squared_error: 26.5670\n",
      "Epoch 133/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 25.2785 - mean_squared_error: 25.2785: 0s - loss: 24.\n",
      "Epoch 134/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.9424 - mean_squared_error: 26.9424\n",
      "Epoch 135/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 25.2751 - mean_squared_error: 25.2751\n",
      "Epoch 136/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 26.0408 - mean_squared_error: 26.0408\n",
      "Epoch 137/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 25.9860 - mean_squared_error: 25.9860\n",
      "Epoch 138/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.9127 - mean_squared_error: 24.9127\n",
      "Epoch 139/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 25.7644 - mean_squared_error: 25.7644\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.3990 - mean_squared_error: 24.3990\n",
      "Epoch 141/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.8394 - mean_squared_error: 24.8394\n",
      "Epoch 142/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.2443 - mean_squared_error: 23.2443\n",
      "Epoch 143/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.5269 - mean_squared_error: 24.5269\n",
      "Epoch 144/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.9218 - mean_squared_error: 23.9218\n",
      "Epoch 145/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.1770 - mean_squared_error: 24.1770\n",
      "Epoch 146/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 24.1439 - mean_squared_error: 24.1439\n",
      "Epoch 147/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.8508 - mean_squared_error: 23.8508\n",
      "Epoch 148/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.8981 - mean_squared_error: 22.8981\n",
      "Epoch 149/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.5958 - mean_squared_error: 23.5958\n",
      "Epoch 150/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.9827 - mean_squared_error: 22.9827\n",
      "Epoch 151/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.8929 - mean_squared_error: 23.8929\n",
      "Epoch 152/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.1499 - mean_squared_error: 23.1499\n",
      "Epoch 153/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.2928 - mean_squared_error: 23.2928\n",
      "Epoch 154/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.3115 - mean_squared_error: 23.3115\n",
      "Epoch 155/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.6026 - mean_squared_error: 22.6026\n",
      "Epoch 156/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.3955 - mean_squared_error: 22.3955\n",
      "Epoch 157/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 23.1415 - mean_squared_error: 23.1415\n",
      "Epoch 158/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.8508 - mean_squared_error: 22.8508\n",
      "Epoch 159/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.3496 - mean_squared_error: 22.3496\n",
      "Epoch 160/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.4537 - mean_squared_error: 22.4537\n",
      "Epoch 161/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 22.6379 - mean_squared_error: 22.6379\n",
      "Epoch 162/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.7587 - mean_squared_error: 20.7587\n",
      "Epoch 163/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 21.3627 - mean_squared_error: 21.3627\n",
      "Epoch 164/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 21.9623 - mean_squared_error: 21.9623\n",
      "Epoch 165/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 21.2348 - mean_squared_error: 21.2348\n",
      "Epoch 166/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 21.5500 - mean_squared_error: 21.5500\n",
      "Epoch 167/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.8542 - mean_squared_error: 20.8542\n",
      "Epoch 168/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.5155 - mean_squared_error: 20.5155\n",
      "Epoch 169/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.3741 - mean_squared_error: 20.3741\n",
      "Epoch 170/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.4092 - mean_squared_error: 20.4092\n",
      "Epoch 171/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 19.6921 - mean_squared_error: 19.6921\n",
      "Epoch 172/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.3588 - mean_squared_error: 20.3588\n",
      "Epoch 173/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 20.2261 - mean_squared_error: 20.2261\n",
      "Epoch 174/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 19.3781 - mean_squared_error: 19.3781\n",
      "Epoch 175/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 19.1884 - mean_squared_error: 19.1884\n",
      "Epoch 176/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 19.5486 - mean_squared_error: 19.5486\n",
      "Epoch 177/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.7968 - mean_squared_error: 18.7968\n",
      "Epoch 178/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.4826 - mean_squared_error: 18.4826\n",
      "Epoch 179/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 19.0407 - mean_squared_error: 19.0407\n",
      "Epoch 180/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.4515 - mean_squared_error: 18.4515\n",
      "Epoch 181/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.3314 - mean_squared_error: 18.3314\n",
      "Epoch 182/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.4448 - mean_squared_error: 18.4448\n",
      "Epoch 183/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.7046 - mean_squared_error: 18.7046\n",
      "Epoch 184/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.4486 - mean_squared_error: 18.4486\n",
      "Epoch 185/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.5632 - mean_squared_error: 18.5632\n",
      "Epoch 186/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.5100 - mean_squared_error: 18.5100\n",
      "Epoch 187/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.6941 - mean_squared_error: 18.6941\n",
      "Epoch 188/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.5638 - mean_squared_error: 17.5638\n",
      "Epoch 189/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.9206 - mean_squared_error: 17.9206\n",
      "Epoch 190/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.2547 - mean_squared_error: 18.2547\n",
      "Epoch 191/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.5337 - mean_squared_error: 17.5337\n",
      "Epoch 192/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.2180 - mean_squared_error: 17.2180\n",
      "Epoch 193/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.0523 - mean_squared_error: 18.0523\n",
      "Epoch 194/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.2032 - mean_squared_error: 18.2032\n",
      "Epoch 195/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 18.1367 - mean_squared_error: 18.1367\n",
      "Epoch 196/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.4460 - mean_squared_error: 17.4460\n",
      "Epoch 197/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.3798 - mean_squared_error: 17.3798: 0s - loss: 17.3807 - mean_squared_error: 17.38\n",
      "Epoch 198/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.5423 - mean_squared_error: 17.5423\n",
      "Epoch 199/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 16.6776 - mean_squared_error: 16.6776\n",
      "Epoch 200/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 17.1416 - mean_squared_error: 17.1416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ee85533a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d27c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.44142954173822\n",
      "67.66494205823776\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "\n",
    "pred= model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7ca299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 42.9658\n",
      "MSE: 4578.544\n",
      "RMSE: 2289.272\n",
      "R-Squared: -0.6152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae=mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: %.4f' % mae)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE: %.3f' % mse)\n",
    "print('RMSE: %.3f' % (mse*(1/2.0)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print('R-Squared: %.4f' % r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b62b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL database update\n",
    "code='nn1'\n",
    "process='Neural_network'\n",
    "datab='standard'\n",
    "depdelay='yes'\n",
    "\n",
    "cur.execute(\"INSERT OR REPLACE INTO parametres(codi,proces,DepDelay, base_dades, MAE, R2, MSE) VALUES(?,?,?,?,?,?,?)\",(code,process,depdelay,datab,'%.3f' % mae,'%.3f' % r2,'%.3f' % mse))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ea836",
   "metadata": {},
   "source": [
    "##### Delete DepDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6feb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdel=df.drop(['DepDelay'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2306310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separem atributs del target\n",
    "\n",
    "target_column = ['ArrDelay'] \n",
    "predictors = list(set(list(dfdel.columns))-set(target_column))\n",
    "dfdel[predictors] = dfdel[predictors]/dfdel[predictors].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae02a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33893, 21)\n",
      "(14526, 21)\n"
     ]
    }
   ],
   "source": [
    "X = dfdel[predictors].values\n",
    "y = dfdel[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbb252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               2200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,301\n",
      "Trainable params: 2,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=21, activation='relu'))\n",
    "# check to see if the regression node should be added\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary() #Print model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbd55cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1060/1060 [==============================] - 1s 789us/step - loss: 3981.8284 - mean_squared_error: 3981.8284\n",
      "Epoch 2/200\n",
      "1060/1060 [==============================] - 1s 773us/step - loss: 2893.8346 - mean_squared_error: 2893.8346\n",
      "Epoch 3/200\n",
      "1060/1060 [==============================] - 1s 775us/step - loss: 2518.0960 - mean_squared_error: 2518.0960\n",
      "Epoch 4/200\n",
      "1060/1060 [==============================] - 1s 761us/step - loss: 1943.1096 - mean_squared_error: 1943.1096\n",
      "Epoch 5/200\n",
      "1060/1060 [==============================] - 1s 763us/step - loss: 1527.3771 - mean_squared_error: 1527.3771\n",
      "Epoch 6/200\n",
      "1060/1060 [==============================] - 1s 773us/step - loss: 984.6956 - mean_squared_error: 984.6956\n",
      "Epoch 7/200\n",
      "1060/1060 [==============================] - 1s 794us/step - loss: 591.8249 - mean_squared_error: 591.8249\n",
      "Epoch 8/200\n",
      "1060/1060 [==============================] - 1s 798us/step - loss: 341.5531 - mean_squared_error: 341.5531\n",
      "Epoch 9/200\n",
      "1060/1060 [==============================] - 1s 816us/step - loss: 175.5308 - mean_squared_error: 175.5308\n",
      "Epoch 10/200\n",
      "1060/1060 [==============================] - 1s 815us/step - loss: 105.5192 - mean_squared_error: 105.5192\n",
      "Epoch 11/200\n",
      "1060/1060 [==============================] - 1s 825us/step - loss: 100.3744 - mean_squared_error: 100.3744\n",
      "Epoch 12/200\n",
      "1060/1060 [==============================] - 1s 833us/step - loss: 67.5251 - mean_squared_error: 67.5251\n",
      "Epoch 13/200\n",
      "1060/1060 [==============================] - 1s 851us/step - loss: 67.6516 - mean_squared_error: 67.6516\n",
      "Epoch 14/200\n",
      "1060/1060 [==============================] - 1s 863us/step - loss: 60.5248 - mean_squared_error: 60.5248\n",
      "Epoch 15/200\n",
      "1060/1060 [==============================] - 1s 887us/step - loss: 51.7876 - mean_squared_error: 51.7876\n",
      "Epoch 16/200\n",
      "1060/1060 [==============================] - 1s 903us/step - loss: 50.6158 - mean_squared_error: 50.6158\n",
      "Epoch 17/200\n",
      "1060/1060 [==============================] - 1s 931us/step - loss: 57.6430 - mean_squared_error: 57.6430\n",
      "Epoch 18/200\n",
      "1060/1060 [==============================] - 1s 933us/step - loss: 53.6615 - mean_squared_error: 53.6615\n",
      "Epoch 19/200\n",
      "1060/1060 [==============================] - 1s 930us/step - loss: 50.8419 - mean_squared_error: 50.8419\n",
      "Epoch 20/200\n",
      "1060/1060 [==============================] - 1s 952us/step - loss: 50.6375 - mean_squared_error: 50.6375\n",
      "Epoch 21/200\n",
      "1060/1060 [==============================] - 1s 911us/step - loss: 54.4431 - mean_squared_error: 54.4431\n",
      "Epoch 22/200\n",
      "1060/1060 [==============================] - 1s 909us/step - loss: 50.7900 - mean_squared_error: 50.7900\n",
      "Epoch 23/200\n",
      "1060/1060 [==============================] - 1s 936us/step - loss: 51.4081 - mean_squared_error: 51.4081\n",
      "Epoch 24/200\n",
      "1060/1060 [==============================] - 1s 941us/step - loss: 57.1517 - mean_squared_error: 57.1517\n",
      "Epoch 25/200\n",
      "1060/1060 [==============================] - 1s 948us/step - loss: 63.9399 - mean_squared_error: 63.9399\n",
      "Epoch 26/200\n",
      "1060/1060 [==============================] - 1s 977us/step - loss: 65.3876 - mean_squared_error: 65.3876\n",
      "Epoch 27/200\n",
      "1060/1060 [==============================] - 1s 982us/step - loss: 59.9594 - mean_squared_error: 59.9594\n",
      "Epoch 28/200\n",
      "1060/1060 [==============================] - 1s 992us/step - loss: 57.7407 - mean_squared_error: 57.7407\n",
      "Epoch 29/200\n",
      "1060/1060 [==============================] - 1s 984us/step - loss: 53.6817 - mean_squared_error: 53.6817\n",
      "Epoch 30/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.8523 - mean_squared_error: 52.8523\n",
      "Epoch 31/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 55.4021 - mean_squared_error: 55.4021\n",
      "Epoch 32/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 63.7955 - mean_squared_error: 63.7955\n",
      "Epoch 33/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.0669 - mean_squared_error: 49.0669\n",
      "Epoch 34/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.3687 - mean_squared_error: 52.3687\n",
      "Epoch 35/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 62.7096 - mean_squared_error: 62.7096\n",
      "Epoch 36/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 55.7721 - mean_squared_error: 55.7721\n",
      "Epoch 37/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.7567 - mean_squared_error: 50.7567\n",
      "Epoch 38/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.3701 - mean_squared_error: 48.3701\n",
      "Epoch 39/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.2409 - mean_squared_error: 49.2409\n",
      "Epoch 40/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.9183 - mean_squared_error: 48.9183\n",
      "Epoch 41/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 53.1247 - mean_squared_error: 53.1247\n",
      "Epoch 42/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.0625 - mean_squared_error: 52.0625\n",
      "Epoch 43/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.1287 - mean_squared_error: 49.1287\n",
      "Epoch 44/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.9741 - mean_squared_error: 52.9741\n",
      "Epoch 45/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.1586 - mean_squared_error: 48.1586\n",
      "Epoch 46/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 63.7061 - mean_squared_error: 63.7061\n",
      "Epoch 47/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 51.3619 - mean_squared_error: 51.3619\n",
      "Epoch 48/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 54.1548 - mean_squared_error: 54.1548\n",
      "Epoch 49/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.8957 - mean_squared_error: 48.8957\n",
      "Epoch 50/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.8802 - mean_squared_error: 46.8802\n",
      "Epoch 51/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 59.9391 - mean_squared_error: 59.9391\n",
      "Epoch 52/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 57.9804 - mean_squared_error: 57.9804\n",
      "Epoch 53/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.3722 - mean_squared_error: 46.3722\n",
      "Epoch 54/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.1073 - mean_squared_error: 45.1073\n",
      "Epoch 55/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 56.9185 - mean_squared_error: 56.9185\n",
      "Epoch 56/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.4395 - mean_squared_error: 50.4395\n",
      "Epoch 57/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.1535 - mean_squared_error: 45.1535\n",
      "Epoch 58/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 58.0658 - mean_squared_error: 58.0658\n",
      "Epoch 59/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.8564 - mean_squared_error: 49.8564\n",
      "Epoch 60/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 54.7354 - mean_squared_error: 54.7354\n",
      "Epoch 61/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.5372 - mean_squared_error: 49.5372\n",
      "Epoch 62/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.8222 - mean_squared_error: 50.8222\n",
      "Epoch 63/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.2914 - mean_squared_error: 49.2914\n",
      "Epoch 64/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.6575 - mean_squared_error: 49.6575\n",
      "Epoch 65/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 53.5298 - mean_squared_error: 53.5298\n",
      "Epoch 66/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.1676 - mean_squared_error: 48.1676\n",
      "Epoch 67/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.6506 - mean_squared_error: 50.6506\n",
      "Epoch 68/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.9711 - mean_squared_error: 46.9711\n",
      "Epoch 69/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.8475 - mean_squared_error: 49.8475\n",
      "Epoch 70/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.6258 - mean_squared_error: 48.6258\n",
      "Epoch 71/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.1972 - mean_squared_error: 48.1972\n",
      "Epoch 72/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.9309 - mean_squared_error: 48.9309\n",
      "Epoch 73/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.7280 - mean_squared_error: 43.7280\n",
      "Epoch 74/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.5237 - mean_squared_error: 47.5237\n",
      "Epoch 75/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.7105 - mean_squared_error: 45.7105\n",
      "Epoch 76/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.4383 - mean_squared_error: 47.4383\n",
      "Epoch 77/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.5984 - mean_squared_error: 42.5984\n",
      "Epoch 78/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.9238 - mean_squared_error: 47.9238\n",
      "Epoch 79/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.2831 - mean_squared_error: 44.2831\n",
      "Epoch 80/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 63.1423 - mean_squared_error: 63.1423\n",
      "Epoch 81/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.7169 - mean_squared_error: 43.7169\n",
      "Epoch 82/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.1154 - mean_squared_error: 48.1154\n",
      "Epoch 83/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.4745 - mean_squared_error: 52.4745\n",
      "Epoch 84/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.8405 - mean_squared_error: 47.8405\n",
      "Epoch 85/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 51.6455 - mean_squared_error: 51.6455\n",
      "Epoch 86/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.4446 - mean_squared_error: 47.4446\n",
      "Epoch 87/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.8775 - mean_squared_error: 43.8775\n",
      "Epoch 88/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.1142 - mean_squared_error: 47.1142\n",
      "Epoch 89/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 41.2301 - mean_squared_error: 41.2301\n",
      "Epoch 90/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 51.2205 - mean_squared_error: 51.2205\n",
      "Epoch 91/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 58.6663 - mean_squared_error: 58.6663\n",
      "Epoch 92/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.9782 - mean_squared_error: 43.9782\n",
      "Epoch 93/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.6532 - mean_squared_error: 52.6532\n",
      "Epoch 94/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.2962 - mean_squared_error: 38.2962\n",
      "Epoch 95/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.9318 - mean_squared_error: 42.9318\n",
      "Epoch 96/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.4008 - mean_squared_error: 46.4008\n",
      "Epoch 97/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.8341 - mean_squared_error: 47.8341\n",
      "Epoch 98/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.8374 - mean_squared_error: 48.8374\n",
      "Epoch 99/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.1189 - mean_squared_error: 39.1189\n",
      "Epoch 100/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.3645 - mean_squared_error: 48.3645\n",
      "Epoch 101/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.0385 - mean_squared_error: 50.0385\n",
      "Epoch 102/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.1409 - mean_squared_error: 45.1409\n",
      "Epoch 103/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.1905 - mean_squared_error: 42.1905\n",
      "Epoch 104/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.1186 - mean_squared_error: 44.1186\n",
      "Epoch 105/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.1853 - mean_squared_error: 44.1853\n",
      "Epoch 106/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.0321 - mean_squared_error: 48.0321\n",
      "Epoch 107/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.4932 - mean_squared_error: 43.4932\n",
      "Epoch 108/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.9330 - mean_squared_error: 44.9330\n",
      "Epoch 109/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.4486 - mean_squared_error: 43.4486\n",
      "Epoch 110/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 41.3002 - mean_squared_error: 41.3002\n",
      "Epoch 111/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.7367 - mean_squared_error: 47.7367\n",
      "Epoch 112/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.5672 - mean_squared_error: 45.5672\n",
      "Epoch 113/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.5215 - mean_squared_error: 47.5215\n",
      "Epoch 114/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 54.5201 - mean_squared_error: 54.5201\n",
      "Epoch 115/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.4985 - mean_squared_error: 45.4985\n",
      "Epoch 116/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 59.9191 - mean_squared_error: 59.9191\n",
      "Epoch 117/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.7838 - mean_squared_error: 48.7838\n",
      "Epoch 118/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.7170 - mean_squared_error: 45.7170\n",
      "Epoch 119/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.6350 - mean_squared_error: 42.6350\n",
      "Epoch 120/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.9356 - mean_squared_error: 42.9356\n",
      "Epoch 121/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 53.7412 - mean_squared_error: 53.7412\n",
      "Epoch 122/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.0630 - mean_squared_error: 46.0630\n",
      "Epoch 123/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.2708 - mean_squared_error: 48.2708\n",
      "Epoch 124/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.7563 - mean_squared_error: 42.7563\n",
      "Epoch 125/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.0912 - mean_squared_error: 43.0912\n",
      "Epoch 126/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.0201 - mean_squared_error: 43.0201\n",
      "Epoch 127/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 48.0266 - mean_squared_error: 48.0266\n",
      "Epoch 128/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 41.6119 - mean_squared_error: 41.6119\n",
      "Epoch 129/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 53.9194 - mean_squared_error: 53.9194\n",
      "Epoch 130/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.7864 - mean_squared_error: 43.7864\n",
      "Epoch 131/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.5869 - mean_squared_error: 50.5869\n",
      "Epoch 132/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 53.9635 - mean_squared_error: 53.9635\n",
      "Epoch 133/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.7389 - mean_squared_error: 43.7389\n",
      "Epoch 134/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.4055 - mean_squared_error: 47.4055\n",
      "Epoch 135/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.6583 - mean_squared_error: 50.6583\n",
      "Epoch 136/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 51.3488 - mean_squared_error: 51.3488\n",
      "Epoch 137/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.0825 - mean_squared_error: 42.0825\n",
      "Epoch 138/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.6169 - mean_squared_error: 38.6169\n",
      "Epoch 139/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.7560 - mean_squared_error: 42.7560\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.7935 - mean_squared_error: 46.7935\n",
      "Epoch 141/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.2081 - mean_squared_error: 45.2081\n",
      "Epoch 142/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.9385 - mean_squared_error: 46.9385\n",
      "Epoch 143/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.7789 - mean_squared_error: 43.7789\n",
      "Epoch 144/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.7025 - mean_squared_error: 50.7025\n",
      "Epoch 145/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.3566 - mean_squared_error: 39.3566\n",
      "Epoch 146/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 54.2789 - mean_squared_error: 54.2789\n",
      "Epoch 147/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.4752 - mean_squared_error: 40.4752\n",
      "Epoch 148/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.7988 - mean_squared_error: 40.7988\n",
      "Epoch 149/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.8559 - mean_squared_error: 48.8559\n",
      "Epoch 150/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.8945 - mean_squared_error: 45.8945\n",
      "Epoch 151/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.5788 - mean_squared_error: 42.5788\n",
      "Epoch 152/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.1995 - mean_squared_error: 44.1995\n",
      "Epoch 153/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.5588 - mean_squared_error: 43.5588\n",
      "Epoch 154/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.1143 - mean_squared_error: 38.1143\n",
      "Epoch 155/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.4457 - mean_squared_error: 43.4457\n",
      "Epoch 156/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.8531 - mean_squared_error: 40.8531\n",
      "Epoch 157/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.8959 - mean_squared_error: 45.8959\n",
      "Epoch 158/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.3892 - mean_squared_error: 45.3892\n",
      "Epoch 159/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.5850 - mean_squared_error: 48.5850\n",
      "Epoch 160/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.0709 - mean_squared_error: 40.0709\n",
      "Epoch 161/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.9728 - mean_squared_error: 44.9728\n",
      "Epoch 162/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.1462 - mean_squared_error: 42.1462\n",
      "Epoch 163/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 43.8866 - mean_squared_error: 43.8866\n",
      "Epoch 164/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.8361 - mean_squared_error: 52.8361\n",
      "Epoch 165/200\n",
      "1060/1060 [==============================] - 2s 2ms/step - loss: 51.8721 - mean_squared_error: 51.8721\n",
      "Epoch 166/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.6304 - mean_squared_error: 47.6304\n",
      "Epoch 167/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.1193 - mean_squared_error: 44.1193\n",
      "Epoch 168/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 46.1304 - mean_squared_error: 46.1304\n",
      "Epoch 169/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 49.8635 - mean_squared_error: 49.8635\n",
      "Epoch 170/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.7023 - mean_squared_error: 46.7023\n",
      "Epoch 171/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 42.3826 - mean_squared_error: 42.3826\n",
      "Epoch 172/200\n",
      "1060/1060 [==============================] - 2s 2ms/step - loss: 43.7411 - mean_squared_error: 43.7411\n",
      "Epoch 173/200\n",
      "1060/1060 [==============================] - 2s 2ms/step - loss: 43.1273 - mean_squared_error: 43.1273\n",
      "Epoch 174/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 40.5215 - mean_squared_error: 40.5215\n",
      "Epoch 175/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 42.3132 - mean_squared_error: 42.3132\n",
      "Epoch 176/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.8146 - mean_squared_error: 39.8146\n",
      "Epoch 177/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.8342 - mean_squared_error: 49.8342\n",
      "Epoch 178/200\n",
      "1060/1060 [==============================] - 2s 1ms/step - loss: 44.5712 - mean_squared_error: 44.5712\n",
      "Epoch 179/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.6391 - mean_squared_error: 47.6391\n",
      "Epoch 180/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.2670 - mean_squared_error: 45.2670\n",
      "Epoch 181/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.0366 - mean_squared_error: 47.0366\n",
      "Epoch 182/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.4242 - mean_squared_error: 44.4242\n",
      "Epoch 183/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.1705 - mean_squared_error: 49.1705\n",
      "Epoch 184/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.2883 - mean_squared_error: 47.2883\n",
      "Epoch 185/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.7412 - mean_squared_error: 39.7412\n",
      "Epoch 186/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.4606 - mean_squared_error: 47.4606\n",
      "Epoch 187/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 48.5753 - mean_squared_error: 48.5753\n",
      "Epoch 188/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.0562 - mean_squared_error: 39.0562\n",
      "Epoch 189/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 45.5429 - mean_squared_error: 45.5429\n",
      "Epoch 190/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 52.6744 - mean_squared_error: 52.6744\n",
      "Epoch 191/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 40.4786 - mean_squared_error: 40.4786\n",
      "Epoch 192/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 50.3235 - mean_squared_error: 50.3235\n",
      "Epoch 193/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 49.2328 - mean_squared_error: 49.2328\n",
      "Epoch 194/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 42.6938 - mean_squared_error: 42.6938\n",
      "Epoch 195/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 44.6767 - mean_squared_error: 44.6767\n",
      "Epoch 196/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 46.4798 - mean_squared_error: 46.4798\n",
      "Epoch 197/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 38.2618 - mean_squared_error: 38.2618\n",
      "Epoch 198/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.3063 - mean_squared_error: 39.3063\n",
      "Epoch 199/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 39.3737 - mean_squared_error: 39.3737\n",
      "Epoch 200/200\n",
      "1060/1060 [==============================] - 1s 1ms/step - loss: 47.2593 - mean_squared_error: 47.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ee8b42eb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7491598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.47817878517914\n",
      "67.70385363256187\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "\n",
    "pred= model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ba39f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 43.0059\n",
      "MSE: 4583.812\n",
      "RMSE: 2291.906\n",
      "R-Squared: -0.6170\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae=mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: %.4f' % mae)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE: %.3f' % mse)\n",
    "print('RMSE: %.3f' % (mse*(1/2.0)))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print('R-Squared: %.4f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce01f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL database update\n",
    "code='nn2'\n",
    "process='Neural_network'\n",
    "datab='standard'\n",
    "depdelay='no'\n",
    "\n",
    "cur.execute(\"INSERT OR REPLACE INTO parametres(codi,proces,DepDelay, base_dades, MAE, R2, MSE) VALUES(?,?,?,?,?,?,?)\",(code,process,depdelay,datab,'%.3f' % mae,'%.3f' % r2,'%.3f' % mse))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e4bbe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "##### Check the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0866ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         codi          proces DepDelay    base_dades     MAE     R2       MSE\n",
      "0         ls1           Lasso      yes      standard   3.548  0.987    44.190\n",
      "1         ls2           Lasso       no      standard   3.548  0.987    44.190\n",
      "2   objective  Neural_network       no  objective_dt  35.110  0.129  2828.555\n",
      "3         dt1   Decision_Tree      yes      standard   5.913  0.976    79.421\n",
      "4         dt2   Decision_Tree      yes      standard   9.374  0.936   198.610\n",
      "5         dt3   Decision_Tree       no      standard  14.571  0.831   517.535\n",
      "6         dt4   Decision_Tree      yes  standard/min   9.374  0.831   198.610\n",
      "7         dt5   Decision_Tree      yes   no standard   9.818  0.831   227.035\n",
      "8         dt6   Decision_Tree       no   no standard  14.717  0.831   493.721\n",
      "9         nn1  Neural_network      yes      standard  42.966 -0.615  4578.544\n",
      "10        nn2  Neural_network       no      standard  43.006 -0.617  4583.812\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_sql_query(\"SELECT * from parametres\", conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c5623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
